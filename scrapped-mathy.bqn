lf â† @+10

inbuiltTokens â† âŸ¨"â‡", "=", "â‹„"âŸ©
map â† "a"â€¿'b' â€¢Hashmap 1â€¿2

Tokenize â† {
  dâ†+`-âŸœÂ»Ë"{}"=âŒœğ•©
  parts â† ğ•©âŠ”Ëœ+`0âˆ¾â‰ ËË˜2â†•d
  depthOfEachPart â† âŠ‘Â¨dâŠ”Ëœ+`0âˆ¾â‰ ËË˜2â†•d

  split â† âˆ§`âˆ˜â‰ âŸœ'#'âŠ¸/Â¨Â¨ lf((âŠ¢-Ëœ+`Ã—Â¬)âˆ˜=âŠ”âŠ¢)Â¨ parts
  blocks â† '{'=(âŠ‘1â†‘âŠ‘)Â¨split
  clean â† (Â¯1â†“1â†“âŠ¢)Â¨âŒ¾(blocksâŠ¸/) split
  identifiers â† ' '((Â¬-ËœâŠ¢Ã—Â·+`Â»âŠ¸>)âˆ˜â‰ âŠ”âŠ¢)Â¨Â¨clean
  tokens â† â·inbuiltTokensâˆ¾âˆ¾âˆ¾identifiers
  (âˆ¾(âŠ‘âˆŠâŸœ(â†•â‰ inbuiltTokens))âŠ¸âˆ¾Â¨)Â¨Â¨tokensâŠ¸âŠÂ¨Â¨identifiers
}
all â† â€¢FChars "nestedLangsTest.bqn"

all Tokenize â†©

â€¢Show all

# # SPACE
# 
# â€¢Show Â»âŠ¸âˆ¨ 0 {
#   ğ•©? 1â€¿0â‰¢ğ•¨
# ;
#   0â€¿0â‰¡ğ•¨
# }Ëœ`<Ë˜â‰(@+10)â€¿' '=âŒœ0/nâ†"hello
#   dwad  
#   wa  dwa
#      dwa
#      awd
#  wada
# a"